{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AIDL Final Notebook.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "MsnPa2cFwr2Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Uncomment below lines on first run\n",
        "# !pip install spacy google-cloud-vision"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cke7hzChzMAz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        },
        "outputId": "dc63f999-8cf4-416e-83b6-5b25c334fc8a"
      },
      "source": [
        "# Unzipping model files\n",
        "! unzip models.zip"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  models.zip\n",
            "   creating: models/AIDL_NER_DO-0.30_EP-20_100_PERC_DATA/\n",
            "  inflating: models/AIDL_NER_DO-0.30_EP-20_100_PERC_DATA/meta.json  \n",
            "   creating: models/AIDL_NER_DO-0.30_EP-20_100_PERC_DATA/ner/\n",
            "  inflating: models/AIDL_NER_DO-0.30_EP-20_100_PERC_DATA/ner/cfg  \n",
            "  inflating: models/AIDL_NER_DO-0.30_EP-20_100_PERC_DATA/ner/model  \n",
            "  inflating: models/AIDL_NER_DO-0.30_EP-20_100_PERC_DATA/ner/moves  \n",
            "  inflating: models/AIDL_NER_DO-0.30_EP-20_100_PERC_DATA/tokenizer  \n",
            "   creating: models/AIDL_NER_DO-0.30_EP-20_100_PERC_DATA/vocab/\n",
            " extracting: models/AIDL_NER_DO-0.30_EP-20_100_PERC_DATA/vocab/key2row  \n",
            "  inflating: models/AIDL_NER_DO-0.30_EP-20_100_PERC_DATA/vocab/lexemes.bin  \n",
            "  inflating: models/AIDL_NER_DO-0.30_EP-20_100_PERC_DATA/vocab/strings.json  \n",
            "  inflating: models/AIDL_NER_DO-0.30_EP-20_100_PERC_DATA/vocab/vectors  \n",
            "   creating: models/AIDL_NER_DO-0.30_EP-20_80_PERC_DATA/\n",
            "  inflating: models/AIDL_NER_DO-0.30_EP-20_80_PERC_DATA/meta.json  \n",
            "   creating: models/AIDL_NER_DO-0.30_EP-20_80_PERC_DATA/ner/\n",
            "  inflating: models/AIDL_NER_DO-0.30_EP-20_80_PERC_DATA/ner/cfg  \n",
            "  inflating: models/AIDL_NER_DO-0.30_EP-20_80_PERC_DATA/ner/model  \n",
            "  inflating: models/AIDL_NER_DO-0.30_EP-20_80_PERC_DATA/ner/moves  \n",
            "  inflating: models/AIDL_NER_DO-0.30_EP-20_80_PERC_DATA/tokenizer  \n",
            "   creating: models/AIDL_NER_DO-0.30_EP-20_80_PERC_DATA/vocab/\n",
            " extracting: models/AIDL_NER_DO-0.30_EP-20_80_PERC_DATA/vocab/key2row  \n",
            "  inflating: models/AIDL_NER_DO-0.30_EP-20_80_PERC_DATA/vocab/lexemes.bin  \n",
            "  inflating: models/AIDL_NER_DO-0.30_EP-20_80_PERC_DATA/vocab/strings.json  \n",
            "  inflating: models/AIDL_NER_DO-0.30_EP-20_80_PERC_DATA/vocab/vectors  \n",
            "   creating: models/AIDL_NER_DO-0.30_EP-20_90_PERC_DATA/\n",
            "  inflating: models/AIDL_NER_DO-0.30_EP-20_90_PERC_DATA/meta.json  \n",
            "   creating: models/AIDL_NER_DO-0.30_EP-20_90_PERC_DATA/ner/\n",
            "  inflating: models/AIDL_NER_DO-0.30_EP-20_90_PERC_DATA/ner/cfg  \n",
            "  inflating: models/AIDL_NER_DO-0.30_EP-20_90_PERC_DATA/ner/model  \n",
            "  inflating: models/AIDL_NER_DO-0.30_EP-20_90_PERC_DATA/ner/moves  \n",
            "  inflating: models/AIDL_NER_DO-0.30_EP-20_90_PERC_DATA/tokenizer  \n",
            "   creating: models/AIDL_NER_DO-0.30_EP-20_90_PERC_DATA/vocab/\n",
            " extracting: models/AIDL_NER_DO-0.30_EP-20_90_PERC_DATA/vocab/key2row  \n",
            "  inflating: models/AIDL_NER_DO-0.30_EP-20_90_PERC_DATA/vocab/lexemes.bin  \n",
            "  inflating: models/AIDL_NER_DO-0.30_EP-20_90_PERC_DATA/vocab/strings.json  \n",
            "  inflating: models/AIDL_NER_DO-0.30_EP-20_90_PERC_DATA/vocab/vectors  \n",
            "  inflating: models/run.py           \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0KSuevWv4dd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importing Libraries\n",
        "import spacy\n",
        "import os \n",
        "import json\n",
        "from google.cloud import vision\n",
        "import io\n",
        "\n",
        "# Setting Environment Variable for Vision API\n",
        "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]=\"/content/fyp-bot-fkvpth-63ef51dcf510.json\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQlvXdE0wW6Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Setting variables\n",
        "modelDir = \"models/AIDL_NER_DO-0.30_EP-20_90_PERC_DATA\"\n",
        "fileType = \"img\"\n",
        "filename = \"sample.jpg\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uxy2g9YTw-Mq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initializing vision API\n",
        "client = vision.ImageAnnotatorClient()\n",
        "\n",
        "# Loading the saved Spacy model\n",
        "nlp = spacy.load(modelDir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aE1LGQBjxEtW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getOutput(type, data):\n",
        "  \"\"\"\n",
        "  Parameters: type: type of data, either img or txt\n",
        "  Output: Prints the dictionary\n",
        "  \"\"\"\n",
        "  textToPredict = \"\"\n",
        "  if (type == \"img\"):\n",
        "    with io.open(data, 'rb') as image_file:\n",
        "        content = image_file.read()\n",
        "        image = vision.types.Image(content=content)\n",
        "        text_response = client.text_detection(image=image)\n",
        "        texts = [text.description for text in text_response.text_annotations]\n",
        "        textToPredict = texts[0]\n",
        "  else:\n",
        "    f = open(data, \"r\")\n",
        "    textToPredict = f.read()\n",
        "  \n",
        "  doc = nlp(textToPredict)\n",
        "  max_amt = 0\n",
        "  i = 1\n",
        "  data = {}\n",
        "  items_list = []\n",
        "  for ent in doc.ents:\n",
        "    if (ent.label_ == \"Total bill amount\"):\n",
        "      try:\n",
        "        amt = float(ent.text)\n",
        "        if amt > max_amt:\n",
        "          data[\"Total bill amount\"] = amt\n",
        "      except Exception as e:\n",
        "        print(e)\n",
        "    elif (ent.label_ == \"Items\"):\n",
        "      try:\n",
        "        items_list.append(ent.text)\n",
        "      except Exception as e:\n",
        "        print(e)\n",
        "    else:\n",
        "      if ent.label_ in data.keys():\n",
        "        data[ent.label_+\"-\"+str(i)] = ent.text\n",
        "        i +=1\n",
        "      else:\n",
        "        data[ent.label_] = ent.text\n",
        "  data[\"Items\"]=items_list\n",
        "  data = dict(sorted(data.items()))\n",
        "  print(json.dumps(data, indent=2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKx5IwLNxHyf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "f595d45f-3aa8-4e74-cacd-e3eec92dce48"
      },
      "source": [
        "%time\n",
        "# Calling the function to get the output\n",
        "getOutput(fileType, filename)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n",
            "Wall time: 7.15 µs\n",
            "{\n",
            "  \"Date\": \"29-11-2019\",\n",
            "  \"Invoice number\": \"201911291623\",\n",
            "  \"Items\": [\n",
            "    \"YOU ARE THE GREATE\\nST MUG-FATHER\",\n",
            "    \"PRINTED PAPER MATT\\nER\\nCRAFT PAPER BAG- H\"\n",
            "  ],\n",
            "  \"Store address\": \"PHOENIX MARKETCITY\\n\",\n",
            "  \"Store address-2\": \"S-23,IIND FLOOR, 142, VELACHERY MAIN ROAD,\\nCHENNAI-600042\",\n",
            "  \"Store name\": \"ARCHIES\",\n",
            "  \"Store name-1\": \"ARCHIES\",\n",
            "  \"Time\": \"16:22\",\n",
            "  \"Total bill amount\": 434.0\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}